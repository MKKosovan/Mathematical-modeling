---
title: "Exercise 2"
author: "Михаил Косован"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Вариант 10  


 1. Построить модели на данных примера 3 с параметрами распределений, соответствующими своему варианту. На графиках сетку с истинной разделяющей границей рисовать не нужно. Определить, какой из методов срабатывает на этих данных лучше, и почему.  
 2. По матрице неточностей той модели, которая оказалась лучше по Acc, рассчитать характеристики качества и ошибки из лекции: TPR, SPC, PPV, NPV, FNR, FPR, FDR, MCC.  
 3.  Выполненные задачи 1-2 разместить в одном отчёте в репозитории на github.com, выслать ссылку на него на почту преподавателя. В репозитории должны лежать:  
   + файл README.md с кратким описанием содержимого репозитория;  
   + скрипт генерации отчёта: файл .Rmd в кодировке UTF-8;  
   + графики, сгенерированные в задании.  
  
Класс $Y = 0: \, X \sim  N((20,21)),  
\begin{pmatrix}
51.84 & 0 \\
0 & 104.04
\end{pmatrix}
)$

Класс $Y = 1: \, X \sim  N((18,31)),  
\begin{pmatrix}
33.64 & 0 \\
0 & 316.84
\end{pmatrix}
)$

# Оценка точности модели с дискретной зависимой переменной (Y)  

В практических примерах ниже показано:

* как рассчитать матрицу неточностей
* как считать показатели качества модели по матрице неточностей
* как пользоваться наивным байесовским классификатором
* как пользоваться методом kNN (k ближайших соседей)  


Модели: наивный байесовский классификатор, kNN (метод k ближайших соседей).
Данные: сгенерированные.

Нам понадобится несколько пакетов для работы с перечисленными методами классификации.  

```{r}
library('class')        # функция knn()
library('e1071')        # функция naiveBayes()
library('MASS')         # функция mvrnorm()

# ядро
my.seed <- 12345


# Генерируем данные ------------------------------------------------------------

#  Пример 2 ....................................................................
n <- 100               # наблюдений всего
train.percent <- 0.85  # доля обучающей выборки

# фактические значения объясняющих переменных (нормальный закон)
set.seed(my.seed)
x1 <- rnorm(20, 7.2, n = n)

set.seed(my.seed + 1)
x2 <- rnorm(21, 10.2, n = n)

# истинные дискриминирующие правила
rules <- function(x1, x2){
    ifelse((x1 > 20 & x2 < 21) | (x1 < 18 & x2 > 31), 1, 0)
}

```

__Задача 1__ Построить модели на данных примера 3 с параметрами распределений, соответствующими своему варианту. На графиках сетку с истинной разделяющей границей рисовать не нужно. Определить, какой из методов срабатывает на этих данных лучше, и почему.


 * $n = 100, \; доля обучающей \; выборки: 85\%$  
 * $Y = 0: \, X \sim  N((20,21)),  
\begin{pmatrix}
7.2^2 & 0 \\
0 & 10.2^2
\end{pmatrix}
)$
 * $Y = 1: \, X \sim  N((18,31)),  
\begin{pmatrix}
5.8^2 & 0 \\
0 & 17.8^2
\end{pmatrix}
)$



```{r}
# Генерируем данные ------------------------------------------------------------

# Данные примера 3 .............................................................
n <- 100               # наблюдений всего
train.percent <- 0.85  # доля обучающей выборки

# x-ы -- двумерные нормальные случайные величины
set.seed(my.seed)
class.0 <- mvrnorm(45, mu = c(20, 21), 
                   Sigma = matrix(c(7.2^2, 0, 0, 10.2^2), 2, 2, 
                                  byrow = T))

set.seed(my.seed + 1)
class.1 <- mvrnorm(55, mu = c(18, 31), 
                   Sigma = matrix(c(5.8^2, 0, 0, 17.8^2), 2, 2, 
                                  byrow = T))

# записываем x-ы в единые векторы (объединяем классы 0 и 1)
x1 <- c(class.0[, 1], class.1[, 1])
x2 <- c(class.0[, 2], class.1[, 2])

# фактические классы Y
y <- c(rep(0, nrow(class.0)), rep(1, nrow(class.1)))

# классы для наблюдений сетки
rules <- function(x1, x2){
    ifelse(x2 < 1.6*x1 + 19, 0, 1)
}
# Конец данных примера 3 .......................................................


# Отбираем наблюдения в обучающую выборку --------------------------------------
set.seed(my.seed)
inTrain <- sample(seq_along(x1), train.percent*n)
x1.train <- x1[inTrain]
x2.train <- x2[inTrain]
x1.test <- x1[-inTrain]
x2.test <- x2[-inTrain]

# используем истинные правила, чтобы присвоить фактические классы
y.train <- y[inTrain]
y.test <- y[-inTrain]

# фрейм с обучающей выборкой
df.train.1 <- data.frame(x1 = x1.train, x2 = x2.train, y = y.train)
# фрейм с тестовой выборкой
df.test.1 <- data.frame(x1 = x1.test, x2 = x2.test)
```
Нарисуем обучающую выборку на графике. Сеткой точек показаны области классов, соответствующие истинным дискриминирующим правилам.

```{r}
# Рисуем обучающую выборку графике ---------------------------------------------

# для сетки (истинных областей классов): целочисленные значения x1, x2
x1.grid <- rep(seq(floor(min(x1)), ceiling(max(x1)), by = 1),
               ceiling(max(x2)) - floor(min(x2)) + 1)
x2.grid <- rep(seq(floor(min(x2)), ceiling(max(x2)), by = 1),
               each = ceiling(max(x1)) - floor(min(x1)) + 1)

# классы для наблюдений сетки
y.grid <- rules(x1.grid, x2.grid)

# фрейм для сетки
df.grid.1 <- data.frame(x1 = x1.grid, x2 = x2.grid, y = y.grid)

# цвета для графиков
cls <- c('blue', 'orange')
cls.t <- c(rgb(0, 0, 1, alpha = 0.5), rgb(1,0.5,0, alpha = 0.5))

# график истинных классов
plot(df.grid.1$x1, df.grid.1$x2, 
     pch = '·', col = cls[df.grid.1[, 'y'] + 1],
     xlab = 'X1', ylab = 'Y1',
     main = 'Training sample, actual')
# точки фактических наблюдений
points(df.train.1$x1, df.train.1$x2,
       pch = 21, bg = cls.t[df.train.1[, 'y'] + 1], 
       col = cls.t[df.train.1[, 'y'] + 1])
```


Обучим модель наивного байесовского классификатора и оценим её точность (верность) на обучающей выборке. Хотя объясняющие переменные для классов сгенерированы как двумерные нормальные распределения, но сами классы перекрываются, не следует ожидать, что эта модель окажется точной.


```{r}
# Байесовский классификатор ----------------------------------------------------
#  наивный байес: непрерывные объясняющие переменные

# строим модель
nb <- naiveBayes(y ~ ., data = df.train.1)
# получаем модельные значения на обучающей выборке как классы
y.nb.train <- ifelse(predict(nb, df.train.1[, -3], 
                             type = "raw")[, 2] > 0.5, 1, 0)

# график истинных классов
plot(df.grid.1$x1, df.grid.1$x2, 
     pch = '·',  col = cls[df.grid.1[, 'y'] + 1], 
     xlab = 'X1', ylab = 'Y1',
     main = 'Training sample, model naiveBayes')
# точки наблюдений, предсказанных по модели
points(df.train.1$x1, df.train.1$x2, 
       pch = 21, bg = cls.t[y.nb.train + 1], 
       col = cls.t[y.nb.train + 1])
```
```{r}
# матрица неточностей на обучающей выборке
tbl <- table(y.train, y.nb.train)
tbl
```
```{r}
# точность, или верность (Accuracy)
Acc <- sum(diag(tbl)) / sum(tbl)
Acc
```

Так и есть. Наивный байесовский метод разделяет классы на обучающей выборке, ошибаясь в 30 наблюдениях.
Сделаем прогноз классов Y на тестовую выборку и оценим точность модели.

```{r}
# прогноз на тестовую выборку
y.nb.test <- ifelse(predict(nb, df.test.1, type = "raw")[, 2] > 0.5, 1, 0)

# матрица неточностей на тестовой выборке
tbl <- table(y.test, y.nb.test)
tbl
```

```{r}
# точность, или верность (Accuracy)
Acc <- sum(diag(tbl)) / sum(tbl)
Acc
```
Построим модель kNN. С этими данными у метода могут возникнуть проблемы, так как классы смешиваются.

```{r}
# Метод kNN --------------------------------------------------------------------
#  k = 3

# строим модель и делаем прогноз
y.knn.train <- knn(train = scale(df.train.1[, -3]), 
                   test = scale(df.train.1[, -3]),
                   cl = df.train.1$y, k = 3)

# график истинных классов
plot(df.grid.1$x1, df.grid.1$x2, 
     pch = '·', col = cls[df.grid.1[, 'y'] + 1],
     xlab = 'X1', ylab = 'Y1',
     main = 'Training sample, kNN model')
# точки наблюдений, предсказанных по модели
points(df.train.1$x1, df.train.1$x2, 
       pch = 21, bg = cls.t[as.numeric(y.knn.train)], 
       col = cls.t[as.numeric(y.knn.train)])
```

```{r}
# матрица неточностей на обучающей выборке
tbl <- table(y.train, y.knn.train)
tbl
```

```{r}
# точность (Accuracy)
Acc <- sum(diag(tbl)) / sum(tbl)
Acc
```
Так и есть. Точность на обучающей выборке только 73%.
Оценка точности на тестовой выборке также показывает, что модель классифицирует неверно 23 наблюдения.

```{r}
# прогноз на тестовую выборку
y.knn.test <- knn(train = scale(df.train.1[, -3]), 
                 test = scale(df.test.1[, -3]),
                 cl = df.train.1$y, k = 3)

# матрица неточностей на тестовой выборке
tbl <- table(y.test, y.knn.test)
tbl
```

```{r}
# точность (Accuracy)
Acc <- sum(diag(tbl)) / sum(tbl)
Acc
```

__Задача 2__
Наиболее точной оказалась наивная байесовская модель: $Acc = 0.7333333$

По матрице неточностей этой модели, которая оказалась лучше по Acc, рассчитаем характеристики качества и ошибки из лекции: TPR, SPC, PPV, NPV, FNR, FPR, FDR, MCC.

```{r}

tbl <- table(y.test, y.nb.test)
trp <- tbl[2,2]/(tbl[2,1]+tbl[2,2])
spc <- tbl[1,1]/(tbl[1,1]+tbl[1,2])
ppv <- tbl[2,2]/(tbl[2,2]+tbl[1,2])
npv <- tbl[1,1]/(tbl[2,1]+tbl[1,1])
fnr <- 1 - trp
frp <- 1- spc
fdr <- 1 - ppv
mcc <- (tbl[2,2]*tbl[1,1]-tbl[1,2]*tbl[2,1])/sqrt((tbl[2,2]+tbl[1,2])*(tbl[2,2]+tbl[2,1])*(tbl[1,1]+tbl[1,2])*(tbl[1,1]+tbl[2,1]))

modelspec <- matrix(c(trp,spc,ppv,npv,fnr,frp,fdr,mcc), ncol = 1, byrow = T)
rownames(modelspec) <- c("TPR", "SPC", "PPV", "NPV", "FNR", "FPR", "FDR", "MCC")
modelspec



```
